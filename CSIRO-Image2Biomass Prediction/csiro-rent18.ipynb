{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270379f7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:21.911997Z",
     "iopub.status.busy": "2025-11-14T07:22:21.911767Z",
     "iopub.status.idle": "2025-11-14T07:22:35.284959Z",
     "shell.execute_reply": "2025-11-14T07:22:35.283719Z"
    },
    "papermill": {
     "duration": 13.379006,
     "end_time": "2025-11-14T07:22:35.286553",
     "exception": false,
     "start_time": "2025-11-14T07:22:21.907547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.py\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1704aa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.293172Z",
     "iopub.status.busy": "2025-11-14T07:22:35.292829Z",
     "iopub.status.idle": "2025-11-14T07:22:35.297952Z",
     "shell.execute_reply": "2025-11-14T07:22:35.297212Z"
    },
    "papermill": {
     "duration": 0.009486,
     "end_time": "2025-11-14T07:22:35.299058",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.289572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "DATA_DIR = Path(\"/kaggle/input/csiro-biomass\")  # Kaggle이면 이렇게, 로컬이면 바꿔줘\n",
    "TRAIN_CSV = DATA_DIR / \"train.csv\"\n",
    "IMAGE_ROOT = DATA_DIR  # image_path가 \"train/xxx.jpg\"라서 root는 DATA_DIR이면 됨\n",
    "\n",
    "OUTPUT_DIR = Path(\"/kaggle/working/\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 15\n",
    "LR = 1e-3\n",
    "IMAGE_SIZE = 224\n",
    "NUM_WORKERS = 4\n",
    "TARGET_NAMES = [\n",
    "    \"Dry_Clover_g\",\n",
    "    \"Dry_Dead_g\",\n",
    "    \"Dry_Green_g\",\n",
    "    \"Dry_Total_g\",\n",
    "    \"GDM_g\",\n",
    "]\n",
    "N_TARGETS = len(TARGET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d212b698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.305729Z",
     "iopub.status.busy": "2025-11-14T07:22:35.305045Z",
     "iopub.status.idle": "2025-11-14T07:22:35.314981Z",
     "shell.execute_reply": "2025-11-14T07:22:35.314446Z"
    },
    "papermill": {
     "duration": 0.014391,
     "end_time": "2025-11-14T07:22:35.316058",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.301667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69adfa4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.322025Z",
     "iopub.status.busy": "2025-11-14T07:22:35.321845Z",
     "iopub.status.idle": "2025-11-14T07:22:35.325621Z",
     "shell.execute_reply": "2025-11-14T07:22:35.325059Z"
    },
    "papermill": {
     "duration": 0.008097,
     "end_time": "2025-11-14T07:22:35.326699",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.318602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data loading, pivot\n",
    "def load_and_pivot_train(train_csv_path: Path):\n",
    "    df = pd.read_csv(train_csv_path)\n",
    "\n",
    "\n",
    "    df = df[[\"image_path\", \"target_name\", \"target\"]]\n",
    "    pivot = df.pivot_table(\n",
    "        index=\"image_path\",\n",
    "        columns=\"target_name\",\n",
    "        values=\"target\"\n",
    "    )\n",
    "\n",
    "    pivot = pivot.dropna(subset=TARGET_NAMES)\n",
    "    pivot = pivot[TARGET_NAMES]\n",
    "    pivot = pivot.reset_index()\n",
    "\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4facb11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.332861Z",
     "iopub.status.busy": "2025-11-14T07:22:35.332317Z",
     "iopub.status.idle": "2025-11-14T07:22:35.337578Z",
     "shell.execute_reply": "2025-11-14T07:22:35.336852Z"
    },
    "papermill": {
     "duration": 0.00952,
     "end_time": "2025-11-14T07:22:35.338693",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.329173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df, image_root: Path, transforms=None, log_target=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_root = image_root\n",
    "        self.transforms = transforms\n",
    "        self.log_target = log_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = self.image_root / row[\"image_path\"]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        targets = row[TARGET_NAMES].values.astype(\"float32\")\n",
    "\n",
    "        if self.log_target:\n",
    "            targets = np.log1p(targets)\n",
    "\n",
    "        targets = torch.from_numpy(targets)\n",
    "\n",
    "        return image, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc39959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.344477Z",
     "iopub.status.busy": "2025-11-14T07:22:35.344253Z",
     "iopub.status.idle": "2025-11-14T07:22:35.348727Z",
     "shell.execute_reply": "2025-11-14T07:22:35.348210Z"
    },
    "papermill": {
     "duration": 0.008566,
     "end_time": "2025-11-14T07:22:35.349715",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.341149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transforms\n",
    "def get_transforms(image_size=224):\n",
    "    train_tfms = T.Compose([\n",
    "        T.Resize((image_size + 32, image_size + 32)),\n",
    "        T.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    val_tfms = T.Compose([\n",
    "        T.Resize((image_size + 32, image_size + 32)),\n",
    "        T.CenterCrop(image_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    return train_tfms, val_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ec4cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.355446Z",
     "iopub.status.busy": "2025-11-14T07:22:35.355226Z",
     "iopub.status.idle": "2025-11-14T07:22:35.359770Z",
     "shell.execute_reply": "2025-11-14T07:22:35.359221Z"
    },
    "papermill": {
     "duration": 0.008708,
     "end_time": "2025-11-14T07:22:35.360831",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.352123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "class BiomassModel(nn.Module):\n",
    "    def __init__(self, n_targets=5):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        except Exception:\n",
    "            backbone = models.resnet18(pretrained=False)\n",
    "\n",
    "        in_features = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.head = nn.Linear(in_features, n_targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        out = self.head(feat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ecf7b32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.366730Z",
     "iopub.status.busy": "2025-11-14T07:22:35.366520Z",
     "iopub.status.idle": "2025-11-14T07:22:35.370498Z",
     "shell.execute_reply": "2025-11-14T07:22:35.369961Z"
    },
    "papermill": {
     "duration": 0.008148,
     "end_time": "2025-11-14T07:22:35.371515",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.363367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# R^2 metric\n",
    "def r2_score_torch(y_true, y_pred):\n",
    "    y_true_mean = torch.mean(y_true, dim=0, keepdim=True)\n",
    "    ss_tot = torch.sum((y_true - y_true_mean) ** 2, dim=0)\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2, dim=0)\n",
    "    eps = 1e-9\n",
    "    r2_per_target = 1 - ss_res / (ss_tot + eps)\n",
    "    r2_mean = torch.mean(r2_per_target).item()\n",
    "    return r2_mean, r2_per_target.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ecd529f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.377287Z",
     "iopub.status.busy": "2025-11-14T07:22:35.377095Z",
     "iopub.status.idle": "2025-11-14T07:22:35.384883Z",
     "shell.execute_reply": "2025-11-14T07:22:35.383477Z"
    },
    "papermill": {
     "duration": 0.012096,
     "end_time": "2025-11-14T07:22:35.386056",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.373960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train\n",
    "def train_one_epoch(model, loader, optimizer, device, loss_fn):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(model, loader, device, loss_fn):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, targets)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        all_targets.append(targets.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "\n",
    "    r2_mean, r2_per_target = r2_score_torch(all_targets, all_preds)\n",
    "\n",
    "    return epoch_loss, r2_mean, r2_per_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "996cafdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:22:35.392052Z",
     "iopub.status.busy": "2025-11-14T07:22:35.391666Z",
     "iopub.status.idle": "2025-11-14T07:25:46.962372Z",
     "shell.execute_reply": "2025-11-14T07:25:46.961338Z"
    },
    "papermill": {
     "duration": 191.575258,
     "end_time": "2025-11-14T07:25:46.963795",
     "exception": false,
     "start_time": "2025-11-14T07:22:35.388537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Pivoted train size: 357\n",
      "Train size: 321 Val size: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n",
      "  Train loss: 3.420958\n",
      "  Val loss: 195.636715\n",
      "  Val CSIRO metric (weighted log-R2): -146.817978\n",
      "    Dry_Clover_g: -7.519646\n",
      "    Dry_Dead_g: -5.198360\n",
      "    Dry_Green_g: -709.165955\n",
      "    Dry_Total_g: -10.367054\n",
      "    GDM_g: -1.838900\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_001.pth\n",
      "  >> New best model saved to /kaggle/working/best_model.pth (score=-146.817978)\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 2/15\n",
      "  Train loss: 1.095264\n",
      "  Val loss: 1.963795\n",
      "  Val CSIRO metric (weighted log-R2): -1.565202\n",
      "    Dry_Clover_g: -0.341017\n",
      "    Dry_Dead_g: -2.182423\n",
      "    Dry_Green_g: -0.224073\n",
      "    Dry_Total_g: -4.211889\n",
      "    GDM_g: -0.866610\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_002.pth\n",
      "  >> New best model saved to /kaggle/working/best_model.pth (score=-1.565202)\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 3/15\n",
      "  Train loss: 0.985683\n",
      "  Val loss: 1.232165\n",
      "  Val CSIRO metric (weighted log-R2): -0.191833\n",
      "    Dry_Clover_g: -0.653687\n",
      "    Dry_Dead_g: -0.048449\n",
      "    Dry_Green_g: -0.182579\n",
      "    Dry_Total_g: -0.149524\n",
      "    GDM_g: 0.075072\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_003.pth\n",
      "  >> New best model saved to /kaggle/working/best_model.pth (score=-0.191833)\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 4/15\n",
      "  Train loss: 1.097268\n",
      "  Val loss: 10.761948\n",
      "  Val CSIRO metric (weighted log-R2): -20.313580\n",
      "    Dry_Clover_g: -0.122761\n",
      "    Dry_Dead_g: -0.880527\n",
      "    Dry_Green_g: -11.475604\n",
      "    Dry_Total_g: -59.951672\n",
      "    GDM_g: -29.137339\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_004.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 5/15\n",
      "  Train loss: 1.009711\n",
      "  Val loss: 1.280130\n",
      "  Val CSIRO metric (weighted log-R2): -0.449970\n",
      "    Dry_Clover_g: -0.359586\n",
      "    Dry_Dead_g: -0.111178\n",
      "    Dry_Green_g: -0.258272\n",
      "    Dry_Total_g: -1.123432\n",
      "    GDM_g: -0.397381\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_005.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 6/15\n",
      "  Train loss: 0.937493\n",
      "  Val loss: 1.132920\n",
      "  Val CSIRO metric (weighted log-R2): -0.121134\n",
      "    Dry_Clover_g: -0.338279\n",
      "    Dry_Dead_g: 0.133182\n",
      "    Dry_Green_g: -0.308965\n",
      "    Dry_Total_g: -0.041501\n",
      "    GDM_g: -0.050109\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_006.pth\n",
      "  >> New best model saved to /kaggle/working/best_model.pth (score=-0.121134)\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 7/15\n",
      "  Train loss: 0.882883\n",
      "  Val loss: 1.266222\n",
      "  Val CSIRO metric (weighted log-R2): -0.240230\n",
      "    Dry_Clover_g: -0.719923\n",
      "    Dry_Dead_g: -0.173411\n",
      "    Dry_Green_g: -0.098440\n",
      "    Dry_Total_g: -0.290737\n",
      "    GDM_g: 0.081363\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_007.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 8/15\n",
      "  Train loss: 0.947817\n",
      "  Val loss: 1.199378\n",
      "  Val CSIRO metric (weighted log-R2): -0.212543\n",
      "    Dry_Clover_g: -0.705196\n",
      "    Dry_Dead_g: 0.085857\n",
      "    Dry_Green_g: -0.045796\n",
      "    Dry_Total_g: -0.487625\n",
      "    GDM_g: 0.090047\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_008.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 9/15\n",
      "  Train loss: 0.944026\n",
      "  Val loss: 3.459071\n",
      "  Val CSIRO metric (weighted log-R2): -2.139768\n",
      "    Dry_Clover_g: -3.250640\n",
      "    Dry_Dead_g: 0.035518\n",
      "    Dry_Green_g: -4.758981\n",
      "    Dry_Total_g: -1.578378\n",
      "    GDM_g: -1.146359\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_009.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 10/15\n",
      "  Train loss: 0.941546\n",
      "  Val loss: 1.095458\n",
      "  Val CSIRO metric (weighted log-R2): -0.073797\n",
      "    Dry_Clover_g: -0.204755\n",
      "    Dry_Dead_g: 0.044517\n",
      "    Dry_Green_g: -0.319018\n",
      "    Dry_Total_g: 0.001853\n",
      "    GDM_g: 0.108419\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_010.pth\n",
      "  >> New best model saved to /kaggle/working/best_model.pth (score=-0.073797)\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 11/15\n",
      "  Train loss: 0.871561\n",
      "  Val loss: 0.972364\n",
      "  Val CSIRO metric (weighted log-R2): 0.071152\n",
      "    Dry_Clover_g: -0.252398\n",
      "    Dry_Dead_g: -0.142628\n",
      "    Dry_Green_g: 0.206779\n",
      "    Dry_Total_g: 0.113226\n",
      "    GDM_g: 0.430779\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_011.pth\n",
      "  >> New best model saved to /kaggle/working/best_model.pth (score=0.071152)\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 12/15\n",
      "  Train loss: 0.926131\n",
      "  Val loss: 1.301032\n",
      "  Val CSIRO metric (weighted log-R2): -0.764685\n",
      "    Dry_Clover_g: -0.131956\n",
      "    Dry_Dead_g: -0.481725\n",
      "    Dry_Green_g: 0.073700\n",
      "    Dry_Total_g: -3.038188\n",
      "    GDM_g: -0.245255\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_012.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 13/15\n",
      "  Train loss: 0.839852\n",
      "  Val loss: 1.047603\n",
      "  Val CSIRO metric (weighted log-R2): 0.007125\n",
      "    Dry_Clover_g: -0.344154\n",
      "    Dry_Dead_g: 0.027974\n",
      "    Dry_Green_g: -0.065913\n",
      "    Dry_Total_g: 0.097024\n",
      "    GDM_g: 0.320696\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_013.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 14/15\n",
      "  Train loss: 0.767570\n",
      "  Val loss: 0.959231\n",
      "  Val CSIRO metric (weighted log-R2): 0.077310\n",
      "    Dry_Clover_g: -0.183812\n",
      "    Dry_Dead_g: -0.122544\n",
      "    Dry_Green_g: 0.164794\n",
      "    Dry_Total_g: 0.111451\n",
      "    GDM_g: 0.416662\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_014.pth\n",
      "  >> New best model saved to /kaggle/working/best_model.pth (score=0.077310)\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Epoch 15/15\n",
      "  Train loss: 0.796558\n",
      "  Val loss: 1.040178\n",
      "  Val CSIRO metric (weighted log-R2): 0.047496\n",
      "    Dry_Clover_g: -0.484486\n",
      "    Dry_Dead_g: 0.191118\n",
      "    Dry_Green_g: -0.060633\n",
      "    Dry_Total_g: 0.210848\n",
      "    GDM_g: 0.380632\n",
      "  Saved epoch checkpoint to /kaggle/working/model_epoch_015.pth\n",
      "  Updated training log CSV at /kaggle/working/training_log.csv\n",
      "\n",
      "Training finished.\n",
      "Best val weighted R2: 0.07731018215417862\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "def main():\n",
    "    set_seed(RANDOM_SEED)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    pivot_df = load_and_pivot_train(TRAIN_CSV)\n",
    "    print(\"Pivoted train size:\", len(pivot_df))\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        pivot_df,\n",
    "        test_size=0.1,\n",
    "        random_state=RANDOM_SEED,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n",
    "\n",
    "    train_tfms, val_tfms = get_transforms(IMAGE_SIZE)\n",
    "\n",
    "    train_ds = BiomassDataset(train_df, IMAGE_ROOT, transforms=train_tfms, log_target=True)\n",
    "    val_ds = BiomassDataset(val_df, IMAGE_ROOT, transforms=val_tfms, log_target=True)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model = BiomassModel(n_targets=N_TARGETS).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_val_r2 = -1e9\n",
    "    best_model_path = OUTPUT_DIR / \"best_model.pth\"\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device, loss_fn)\n",
    "        print(f\"  Train loss: {train_loss:.6f}\")\n",
    "\n",
    "        val_loss, val_w_r2, val_r2_per_target = validate_one_epoch(\n",
    "            model, val_loader, device, loss_fn\n",
    "        )\n",
    "        print(f\"  Val loss: {val_loss:.6f}\")\n",
    "        print(f\"  Val CSIRO metric (weighted log-R2): {val_w_r2:.6f}\")\n",
    "        for name, r2v in zip(TARGET_NAMES, val_r2_per_target):\n",
    "            print(f\"    {name}: {r2v:.6f}\")\n",
    "\n",
    "        epoch_ckpt_path = OUTPUT_DIR / f\"model_epoch_{epoch:03d}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_weighted_r2\": val_w_r2,\n",
    "                \"val_r2_per_target\": val_r2_per_target,\n",
    "                \"target_names\": TARGET_NAMES,\n",
    "            },\n",
    "            epoch_ckpt_path,\n",
    "        )\n",
    "        print(f\"  Saved epoch checkpoint to {epoch_ckpt_path}\")\n",
    "\n",
    "        if val_w_r2 > best_val_r2:\n",
    "            best_val_r2 = val_w_r2\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"best_val_weighted_r2\": best_val_r2,\n",
    "                    \"target_names\": TARGET_NAMES,\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "            print(f\"  >> New best model saved to {best_model_path} (score={best_val_r2:.6f})\")\n",
    "\n",
    "        row = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"val_weighted_r2\": float(val_w_r2),\n",
    "        }\n",
    "        for name, r2v in zip(TARGET_NAMES, val_r2_per_target):\n",
    "            row[f\"r2_{name}\"] = float(r2v)\n",
    "        history.append(row)\n",
    "\n",
    "        log_df = pd.DataFrame(history)\n",
    "        log_path = OUTPUT_DIR / \"training_log.csv\"\n",
    "        log_df.to_csv(log_path, index=False)\n",
    "        print(f\"  Updated training log CSV at {log_path}\")\n",
    "\n",
    "    print(\"\\nTraining finished.\")\n",
    "    print(\"Best val weighted R2:\", best_val_r2)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5483162b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:25:46.974341Z",
     "iopub.status.busy": "2025-11-14T07:25:46.973768Z",
     "iopub.status.idle": "2025-11-14T07:25:46.978700Z",
     "shell.execute_reply": "2025-11-14T07:25:46.978108Z"
    },
    "papermill": {
     "duration": 0.011296,
     "end_time": "2025-11-14T07:25:46.979736",
     "exception": false,
     "start_time": "2025-11-14T07:25:46.968440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make_submission.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"/kaggle/input/csiro-biomass\")\n",
    "TEST_CSV = DATA_DIR / \"test.csv\"\n",
    "IMAGE_ROOT = DATA_DIR\n",
    "\n",
    "MODEL_PATH = Path(\"/kaggle/working//best_model.pth\")\n",
    "SUBMISSION_PATH = Path(\"/kaggle/working/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6c1e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:25:46.989276Z",
     "iopub.status.busy": "2025-11-14T07:25:46.988775Z",
     "iopub.status.idle": "2025-11-14T07:25:46.992047Z",
     "shell.execute_reply": "2025-11-14T07:25:46.991575Z"
    },
    "papermill": {
     "duration": 0.008977,
     "end_time": "2025-11-14T07:25:46.992986",
     "exception": false,
     "start_time": "2025-11-14T07:25:46.984009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "TARGET_NAMES = [\n",
    "    \"Dry_Clover_g\",\n",
    "    \"Dry_Dead_g\",\n",
    "    \"Dry_Green_g\",\n",
    "    \"Dry_Total_g\",\n",
    "    \"GDM_g\",\n",
    "]\n",
    "N_TARGETS = len(TARGET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bbff6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:25:47.002339Z",
     "iopub.status.busy": "2025-11-14T07:25:47.002146Z",
     "iopub.status.idle": "2025-11-14T07:25:47.007323Z",
     "shell.execute_reply": "2025-11-14T07:25:47.006840Z"
    },
    "papermill": {
     "duration": 0.011106,
     "end_time": "2025-11-14T07:25:47.008343",
     "exception": false,
     "start_time": "2025-11-14T07:25:46.997237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "class BiomassModel(nn.Module):\n",
    "    def __init__(self, n_targets=5):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        except Exception:\n",
    "            backbone = models.resnet18(pretrained=False)\n",
    "\n",
    "        in_features = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.head = nn.Linear(in_features, n_targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        out = self.head(feat)\n",
    "        return out\n",
    "\n",
    "def get_infer_transform(image_size=224):\n",
    "    tfms = T.Compose([\n",
    "        T.Resize((image_size + 32, image_size + 32)),\n",
    "        T.CenterCrop(image_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ])\n",
    "    return tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2b62a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:25:47.017680Z",
     "iopub.status.busy": "2025-11-14T07:25:47.017457Z",
     "iopub.status.idle": "2025-11-14T07:25:47.022012Z",
     "shell.execute_reply": "2025-11-14T07:25:47.021481Z"
    },
    "papermill": {
     "duration": 0.010324,
     "end_time": "2025-11-14T07:25:47.023030",
     "exception": false,
     "start_time": "2025-11-14T07:25:47.012706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, image_root: Path, transforms=None):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.image_root = image_root\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_rel_path = self.image_paths[idx]\n",
    "        img_path = self.image_root / img_rel_path\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, img_rel_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7012ef19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:25:47.032090Z",
     "iopub.status.busy": "2025-11-14T07:25:47.031893Z",
     "iopub.status.idle": "2025-11-14T07:26:19.737182Z",
     "shell.execute_reply": "2025-11-14T07:26:19.736070Z"
    },
    "papermill": {
     "duration": 32.711569,
     "end_time": "2025-11-14T07:26:19.738713",
     "exception": false,
     "start_time": "2025-11-14T07:25:47.027144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rows: 5\n",
      "Unique test images: 1\n",
      "Submission saved to: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    model = BiomassModel(n_targets=N_TARGETS)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    print(\"Test rows:\", len(test_df))\n",
    "\n",
    "    unique_image_paths = test_df[\"image_path\"].unique()\n",
    "    print(\"Unique test images:\", len(unique_image_paths))\n",
    "\n",
    "    tfms = get_infer_transform(IMAGE_SIZE)\n",
    "    test_ds = TestImageDataset(unique_image_paths, IMAGE_ROOT, transforms=tfms)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    image_to_pred_log = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, img_rel_paths in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)  \n",
    "\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            for img_rel_path, pred_log in zip(img_rel_paths, outputs):\n",
    "                image_to_pred_log[img_rel_path] = pred_log\n",
    "\n",
    "    preds = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        sample_id = row[\"sample_id\"]\n",
    "        img_rel_path = row[\"image_path\"]\n",
    "        target_name = row[\"target_name\"]\n",
    "\n",
    "        log_preds = image_to_pred_log[img_rel_path] \n",
    "\n",
    "        idx = TARGET_NAMES.index(target_name)\n",
    "\n",
    "        val = np.expm1(log_preds[idx])\n",
    "\n",
    "        val = float(max(val, 0.0))\n",
    "\n",
    "        preds.append((sample_id, val))\n",
    "    sub_df = pd.DataFrame(preds, columns=[\"sample_id\", \"target\"])\n",
    "    sub_df = sub_df.sort_values(\"sample_id\") \n",
    "    sub_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "\n",
    "    print(\"Submission saved to:\", SUBMISSION_PATH)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 244.265232,
   "end_time": "2025-11-14T07:26:22.154544",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T07:22:17.889312",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
